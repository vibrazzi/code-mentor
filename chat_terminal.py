"""
Script de chat interativo com CodeMentor via Ollama
"""

import asyncio
import time

from core import PROMPT_SISTEMA, call_ollama


async def gerar_resposta_ollama(mensagem, historico=None):
    """Gera resposta usando Ollama com contexto de conversa"""

    if historico is None:
        historico = []

    contexto = "\n".join([
        f"UsuÃ¡rio: {msg['user']}\nCodeMentor: {msg['assistant']}"
        for msg in historico[-3:]
    ])

    prompt = f"""{PROMPT_SISTEMA}

Contexto da conversa anterior:
{contexto}

UsuÃ¡rio atual: {mensagem}

Responda como CodeMentor, focando em lÃ³gica de programaÃ§Ã£o:"""

    try:
        resposta = await call_ollama(prompt, stream=False)
        return resposta

    except Exception as e:
        return f"âŒ Erro ao conectar com Ollama: {e}"


def chat_interativo():
    """Interface de chat interativo no terminal"""

    print("ğŸ¤– CodeMentor - Seu mentor de lÃ³gica de programaÃ§Ã£o")
    print("=" * 50)
    print("Digite suas perguntas sobre lÃ³gica de programaÃ§Ã£o.")
    print("Digite 'sair' para encerrar o chat.")
    print()

    historico = []

    while True:
        try:
            mensagem = input("VocÃª: ").strip()

            if not mensagem:
                continue

            if mensagem.lower() in ['sair', 'quit', 'exit']:
                print("ğŸ‘‹ AtÃ© logo! Continue praticando lÃ³gica de programaÃ§Ã£o!")
                break

            print("ğŸ¤” CodeMentor estÃ¡ pensando...")

            resposta = asyncio.run(gerar_resposta_ollama(mensagem, historico))

            historico.append({"user": mensagem, "assistant": resposta})

            if len(historico) > 5:
                historico = historico[-5:]

            print(f"ğŸ¤– CodeMentor: {resposta}")
            print("-" * 50)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Chat encerrado pelo usuÃ¡rio.")
            break
        except Exception as e:
            print(f"âŒ Erro: {e}")
            break

if __name__ == "__main__":
    chat_interativo()
