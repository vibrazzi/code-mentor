"""
Script de chat interativo com CodeMentor via Ollama
"""

import requests
import time

OLLAMA_URL = "http://localhost:11434/api/generate"

def gerar_resposta_ollama(mensagem, historico=None):
    """Gera resposta usando Ollama com contexto de conversa"""

    if historico is None:
        historico = []

    prompt = f"""VocÃª Ã© o CodeMentor, um experiente mentor de lÃ³gica de programaÃ§Ã£o.

Sua personalidade:
- VocÃª Ã© paciente, didÃ¡tico e encorajador
- Explica conceitos de forma clara e progressiva
- Usa analogias e exemplos prÃ¡ticos
- Incentiva o aprendizado ativo
- MantÃ©m o foco em lÃ³gica de programaÃ§Ã£o

Contexto da conversa anterior:
{chr(10).join([f"UsuÃ¡rio: {msg['user']}{chr(10)}CodeMentor: {msg['assistant']}" for msg in historico[-3:]])}

UsuÃ¡rio atual: {mensagem}

Responda como CodeMentor, focando em lÃ³gica de programaÃ§Ã£o:"""

    payload = {
        "model": "llama3.2:3b",
        "prompt": prompt,
        "stream": False,
        "options": {
            "temperature": 0.7,
            "top_p": 0.9,
        "num_predict": 300
        }
    }

    try:
        response = requests.post(OLLAMA_URL, json=payload, timeout=15)
        response.raise_for_status()

        data = response.json()
        resposta = data.get("response", "").strip()

        return resposta

    except requests.exceptions.RequestException as e:
        return f"âŒ Erro ao conectar com Ollama: {e}"

def chat_interativo():
    """Interface de chat interativo no terminal"""

    print("ğŸ¤– CodeMentor - Seu mentor de lÃ³gica de programaÃ§Ã£o")
    print("=" * 50)
    print("Digite suas perguntas sobre lÃ³gica de programaÃ§Ã£o.")
    print("Digite 'sair' para encerrar o chat.")
    print()

    historico = []

    while True:
        try:
            mensagem = input("VocÃª: ").strip()

            if not mensagem:
                continue

            if mensagem.lower() in ['sair', 'quit', 'exit']:
                print("ğŸ‘‹ AtÃ© logo! Continue praticando lÃ³gica de programaÃ§Ã£o!")
                break

            print("ğŸ¤” CodeMentor estÃ¡ pensando...")

            time.sleep(1)

            resposta = gerar_resposta_ollama(mensagem, historico)

            historico.append({"user": mensagem, "assistant": resposta})

            if len(historico) > 5:
                historico = historico[-5:]

            print(f"ğŸ¤– CodeMentor: {resposta}")
            print("-" * 50)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ Chat encerrado pelo usuÃ¡rio.")
            break
        except Exception as e:
            print(f"âŒ Erro: {e}")
            break

if __name__ == "__main__":
    chat_interativo()
